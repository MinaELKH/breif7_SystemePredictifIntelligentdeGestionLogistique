{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8556c95-185e-4256-a17f-d3259e78e2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Pipeline sauvegardé avec succès!\n",
      "✓ Métadonnées sauvegardées !\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline, Transformer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col, expr\n",
    "import json\n",
    "\n",
    "# ---------- Winsorizer ----------\n",
    "class Winsorizer(Transformer):\n",
    "    def __init__(self, inputCols=None, lower=0.01, upper=0.99):\n",
    "        super(Winsorizer, self).__init__()\n",
    "        self.inputCols = inputCols\n",
    "        self.lower = lower\n",
    "        self.upper = upper\n",
    "    \n",
    "    def _transform(self, df):\n",
    "        for c in self.inputCols:\n",
    "            low, up = df.approxQuantile(c, [self.lower, self.upper], 0.01)\n",
    "            df = df.withColumn(\n",
    "                c,\n",
    "                expr(\n",
    "                    f\"CASE WHEN `{c}` < {low} THEN {low} \"\n",
    "                    f\"WHEN `{c}` > {up} THEN {up} ELSE `{c}` END\"\n",
    "                )\n",
    "            )\n",
    "        return df\n",
    "\n",
    "# ---------- Spark ----------\n",
    "spark = SparkSession.builder.appName(\"ML_Models_Test\").getOrCreate()\n",
    "\n",
    "# ---------- Colonnes ----------\n",
    "feature_numeric_cols = [\n",
    "    \"Days for shipment (scheduled)\", \"Benefit per order\", \"Sales per customer\",\n",
    "    \"Order Item Discount\", \"Order Item Discount Rate\", \"Order Item Product Price\",\n",
    "    \"Order Item Profit Ratio\", \"Order Item Quantity\", \"Sales\", \"Order Profit Per Order\"\n",
    "]\n",
    "\n",
    "feature_categorical_cols = [\n",
    "    \"Type\", \"Shipping Mode\", \"Market\", \"Customer Segment\",\n",
    "    \"Order Region\", \"Category Name\"\n",
    "]\n",
    "\n",
    "# ---------- Data ----------\n",
    "df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", True)\n",
    "    .csv(\"../data/DataCoSupplyChainDataset.csv\")\n",
    "    .filter(col(\"Delivery Status\") != \"Shipping canceled\")\n",
    "    .select(*(feature_numeric_cols + feature_categorical_cols + [\"Late_delivery_risk\"]))\n",
    ").dropna()\n",
    "\n",
    "# ---------- Apply Winsorizer BEFORE pipeline ----------\n",
    "winsor = Winsorizer(inputCols=feature_numeric_cols, lower=0.01, upper=0.99)\n",
    "df = winsor.transform(df)\n",
    "\n",
    "# ---------- Prétraitement ----------\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\")\n",
    "    for c in feature_categorical_cols\n",
    "]\n",
    "\n",
    "assembler_num = VectorAssembler(inputCols=feature_numeric_cols, outputCol=\"num_features\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"num_features\", outputCol=\"num_features_scaled\",\n",
    "                        withMean=True, withStd=True)\n",
    "\n",
    "assembler_final = VectorAssembler(\n",
    "    inputCols=[\"num_features_scaled\"] + [c+\"_idx\" for c in feature_categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# ---------- Modèles ----------\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(featuresCol=\"features\", labelCol=\"Late_delivery_risk\", maxIter=50),\n",
    "}\n",
    "\n",
    "# ---------- Train/Test ----------\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# ---------- Entraînement ----------\n",
    "classifier = models[\"LogisticRegression\"]\n",
    "pipeline = Pipeline(stages=indexers + [assembler_num, scaler, assembler_final, classifier])\n",
    "best_model = pipeline.fit(train)\n",
    "\n",
    "# ---------- Sauvegarde modèle OK ----------\n",
    "model_path = \"../models/logistic_regression_pipeline\"\n",
    "best_model.write().overwrite().save(model_path)\n",
    "print(\"✓ Pipeline sauvegardé avec succès!\")\n",
    "\n",
    "# ---------- Sauvegarde Metadata ----------\n",
    "metadata = {\n",
    "    \"model_type\": \"LogisticRegression\",\n",
    "    \"feature_numeric_cols\": feature_numeric_cols,\n",
    "    \"feature_categorical_cols\": feature_categorical_cols\n",
    "}\n",
    "\n",
    "with open(\"../models/model_metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"✓ Métadonnées sauvegardées !\")\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc9380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
