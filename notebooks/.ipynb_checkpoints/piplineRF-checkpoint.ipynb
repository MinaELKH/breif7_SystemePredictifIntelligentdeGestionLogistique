{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e4e6e-6204-4f65-9961-ae98830543e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# --- Spark ---\n",
    "spark = SparkSession.builder.appName(\"count_test\").getOrCreate()\n",
    "\n",
    "# --- Colonnes ---\n",
    "feature_numeric_cols = [\n",
    "    \"Days for shipment (scheduled)\", \"Benefit per order\", \"Sales per customer\",\n",
    "    \"Order Item Discount\", \"Order Item Discount Rate\", \"Order Item Product Price\",\n",
    "    \"Order Item Profit Ratio\", \"Order Item Quantity\", \"Sales\", \"Order Profit Per Order\"\n",
    "]\n",
    "\n",
    "feature_categorical_cols = [\n",
    "    \"Type\", \"Shipping Mode\", \"Market\", \"Customer Segment\",\n",
    "    \"Order Region\", \"Category Name\"\n",
    "]\n",
    "\n",
    "# --- Charger donn√©es ---\n",
    "df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", True)\n",
    "    .csv(\"../data/DataCoSupplyChainDataset.csv\")\n",
    "    .filter(col(\"Delivery Status\") != \"Shipping canceled\")\n",
    "    .select(*(feature_numeric_cols + feature_categorical_cols + [\"Late_delivery_risk\"]))\n",
    ").dropna()\n",
    "\n",
    "\n",
    "for c in feature_categorical_cols:\n",
    "    print(c, df.select(c).distinct().count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313918c8-09f6-4aeb-85cb-02df1b0298a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - AUC = 0.7284820922900427\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# üîπ Cr√©er SparkSession\n",
    "spark = SparkSession.builder.appName(\"RF_test\").getOrCreate()\n",
    "\n",
    "# üîπ Colonnes\n",
    "feature_numeric_cols = [\n",
    "    \"Days for shipment (scheduled)\", \"Benefit per order\", \"Sales per customer\",\n",
    "    \"Order Item Discount\", \"Order Item Discount Rate\", \"Order Item Product Price\",\n",
    "    \"Order Item Profit Ratio\", \"Order Item Quantity\", \"Sales\", \"Order Profit Per Order\"\n",
    "]\n",
    "\n",
    "feature_categorical_cols = [\n",
    "    \"Type\", \"Shipping Mode\", \"Market\", \"Customer Segment\",\n",
    "    \"Order Region\", \"Category Name\"\n",
    "]\n",
    "\n",
    "# üîπ Charger les donn√©es\n",
    "df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", True)\n",
    "    .csv(\"../data/DataCoSupplyChainDataset.csv\")\n",
    "    .filter(col(\"Delivery Status\") != \"Shipping canceled\")\n",
    "    .select(*(feature_numeric_cols + feature_categorical_cols + [\"Late_delivery_risk\"]))\n",
    ").dropna()\n",
    "\n",
    "# üîπ Pr√©traitement\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_indexed\", handleInvalid=\"keep\") for c in feature_categorical_cols]\n",
    "\n",
    "assembler_num = VectorAssembler(inputCols=feature_numeric_cols, outputCol=\"num_features\")\n",
    "scaler = StandardScaler(inputCol=\"num_features\", outputCol=\"num_features_scaled\", withMean=True, withStd=True)\n",
    "assembler_final = VectorAssembler(inputCols=[\"num_features_scaled\"] + [c+\"_indexed\" for c in feature_categorical_cols], outputCol=\"features\")\n",
    "\n",
    "# üîπ Mod√®le\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"Late_delivery_risk\", maxBins=2000)\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler_num, scaler, assembler_final, rf])\n",
    "\n",
    "# üîπ Train/Test split\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# üîπ Entra√Ænement et pr√©diction\n",
    "model = pipeline.fit(train)\n",
    "pred = model.transform(test)\n",
    "\n",
    "# üîπ √âvaluation\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Late_delivery_risk\", rawPredictionCol=\"rawPrediction\")\n",
    "print(\"Random Forest - AUC =\", evaluator.evaluate(pred))\n",
    "\n",
    "# üîπ Stop Spark pour lib√©rer m√©moire\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d81e12-0a17-4a5f-8122-8df9688a2071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcd4d6a8-9715-43df-beb2-d017f5efd89e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT AUC = 0.7437711704542939\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# --- Spark ---\n",
    "spark = SparkSession.builder.appName(\"GBT_test\").getOrCreate()\n",
    "\n",
    "# --- Colonnes ---\n",
    "feature_numeric_cols = [\n",
    "    \"Days for shipment (scheduled)\", \"Benefit per order\", \"Sales per customer\",\n",
    "    \"Order Item Discount\", \"Order Item Discount Rate\", \"Order Item Product Price\",\n",
    "    \"Order Item Profit Ratio\", \"Order Item Quantity\", \"Sales\", \"Order Profit Per Order\"\n",
    "]\n",
    "\n",
    "feature_categorical_cols = [\n",
    "    \"Type\", \"Shipping Mode\", \"Market\", \"Customer Segment\",\n",
    "     \"Order Region\", \"Category Name\"\n",
    "]\n",
    "\n",
    "# --- Charger donn√©es ---\n",
    "df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", True)\n",
    "    .csv(\"../data/DataCoSupplyChainDataset.csv\")\n",
    "    .filter(col(\"Delivery Status\") != \"Shipping canceled\")\n",
    "    .select(*(feature_numeric_cols + feature_categorical_cols + [\"Late_delivery_risk\"]))\n",
    ").dropna()\n",
    "\n",
    "# --- Encodage simple ---\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\") for c in feature_categorical_cols]\n",
    "\n",
    "# --- Assemblage simple ---\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_numeric_cols + [c+\"_idx\" for c in feature_categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# --- Mod√®le seul ---\n",
    "gbt = GBTClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"Late_delivery_risk\",\n",
    "    maxIter=30,\n",
    "    maxDepth=5,\n",
    "    maxBins=2000\n",
    "    \n",
    ")\n",
    "\n",
    "pipeline = Pipeline(stages=indexers + [assembler, gbt])\n",
    "\n",
    "# --- Train/Test ---\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# --- Train ---\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# --- Pr√©diction ---\n",
    "pred = model.transform(test)\n",
    "\n",
    "# --- AUC ---\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Late_delivery_risk\",\n",
    "    rawPredictionCol=\"rawPrediction\"\n",
    ")\n",
    "\n",
    "print(\"GBT AUC =\", evaluator.evaluate(pred))\n",
    "\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80a0d424-69fd-48e8-91ac-b267d72cda97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 4\n",
      "Shipping Mode 4\n",
      "Market 5\n",
      "Customer Segment 3\n",
      "Order Region 23\n",
      "Category Name 50\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fba10ab7-fc89-49cb-8301-9c1846f10e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== GBTClassifier ===\n",
      "Accuracy = 0.697117903930131\n",
      "F1-score = 0.6936591440259341\n",
      "Precision = 0.7463293681199681\n",
      "Recall = 0.697117903930131\n",
      "AUC = 0.7437733536319574\n",
      "\n",
      "=== RandomForest ===\n",
      "Accuracy = 0.6940902474526929\n",
      "F1-score = 0.6923440477551527\n",
      "Precision = 0.7323106600794665\n",
      "Recall = 0.6940902474526929\n",
      "AUC = 0.728468255710722\n",
      "\n",
      "=== LogisticRegression ===\n",
      "Accuracy = 0.6939737991266376\n",
      "F1-score = 0.6922342061251481\n",
      "Precision = 0.7321398439841479\n",
      "Recall = 0.6939737991266376\n",
      "AUC = 0.7177301771967515\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import GBTClassifier, RandomForestClassifier, LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# --- Spark ---\n",
    "spark = SparkSession.builder.appName(\"ML_Models_Test\").getOrCreate()\n",
    "\n",
    "# --- Colonnes num√©riques et cat√©gorielles ---\n",
    "feature_numeric_cols = [\n",
    "    \"Days for shipment (scheduled)\", \"Benefit per order\", \"Sales per customer\",\n",
    "    \"Order Item Discount\", \"Order Item Discount Rate\", \"Order Item Product Price\",\n",
    "    \"Order Item Profit Ratio\", \"Order Item Quantity\", \"Sales\", \"Order Profit Per Order\"\n",
    "]\n",
    "\n",
    "feature_categorical_cols = [\n",
    "    \"Type\", \"Shipping Mode\", \"Market\", \"Customer Segment\",\n",
    "    \"Order Region\", \"Category Name\"   # Exclu \"Order State\" qui avait trop de valeurs\n",
    "]\n",
    "\n",
    "# --- Charger donn√©es ---\n",
    "df = (\n",
    "    spark.read.option(\"header\", True).option(\"inferSchema\", True)\n",
    "    .csv(\"../data/DataCoSupplyChainDataset.csv\")\n",
    "    .filter(col(\"Delivery Status\") != \"Shipping canceled\")\n",
    "    .select(*(feature_numeric_cols + feature_categorical_cols + [\"Late_delivery_risk\"]))\n",
    ").dropna()\n",
    "\n",
    "# --- Encodage simple ---\n",
    "indexers = [StringIndexer(inputCol=c, outputCol=c+\"_idx\", handleInvalid=\"keep\") for c in feature_categorical_cols]\n",
    "\n",
    "# --- Assemblage ---\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=feature_numeric_cols + [c+\"_idx\" for c in feature_categorical_cols],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "# --- Train/Test ---\n",
    "train, test = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# --- Liste des mod√®les √† tester ---\n",
    "models = {\n",
    "    \"GBTClassifier\": GBTClassifier(featuresCol=\"features\", labelCol=\"Late_delivery_risk\", maxIter=30, maxDepth=5, maxBins=2000),\n",
    "    \"RandomForest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"Late_delivery_risk\", numTrees=50, maxDepth=5, maxBins=2000),\n",
    "    \"LogisticRegression\": LogisticRegression(featuresCol=\"features\", labelCol=\"Late_delivery_risk\", maxIter=50)\n",
    "}\n",
    "\n",
    "# --- Fonction d'√©valuation ---\n",
    "def evaluate_model(model_name, pipeline_model):\n",
    "    pred = pipeline_model.transform(test)\n",
    "    \n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "    evaluator_prec = MulticlassClassificationEvaluator(labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedPrecision\")\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"Late_delivery_risk\", predictionCol=\"prediction\", metricName=\"weightedRecall\")\n",
    "    evaluator_auc = BinaryClassificationEvaluator(labelCol=\"Late_delivery_risk\", rawPredictionCol=\"rawPrediction\")\n",
    "    \n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    print(\"Accuracy =\", evaluator_acc.evaluate(pred))\n",
    "    print(\"F1-score =\", evaluator_f1.evaluate(pred))\n",
    "    print(\"Precision =\", evaluator_prec.evaluate(pred))\n",
    "    print(\"Recall =\", evaluator_recall.evaluate(pred))\n",
    "    print(\"AUC =\", evaluator_auc.evaluate(pred))\n",
    "\n",
    "# --- Entra√Ænement et √©valuation mod√®le par mod√®le ---\n",
    "for name, classifier in models.items():\n",
    "    pipeline = Pipeline(stages=indexers + [assembler, classifier])\n",
    "    model = pipeline.fit(train)\n",
    "    evaluate_model(name, model)\n",
    "\n",
    "# --- Stop Spark ---\n",
    "spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
